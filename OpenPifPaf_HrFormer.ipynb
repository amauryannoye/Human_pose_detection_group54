{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amauryannoye/Human_pose_detection_group54/blob/main/OpenPifPaf_HrFormer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open PifPaf+ HrFormer"
      ],
      "metadata": {
        "id": "-Tq4DTm1Rqoy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV_ytp7PyIqr",
        "outputId": "cfd57ef3-6e8e-44f9-a4f2-42f5a3cbb036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vita-epfl-openpifpaf'...\n",
            "remote: Enumerating objects: 14097, done.\u001b[K\n",
            "remote: Counting objects: 100% (527/527), done.\u001b[K\n",
            "remote: Compressing objects: 100% (274/274), done.\u001b[K\n",
            "remote: Total 14097 (delta 204), reused 493 (delta 192), pack-reused 13570\u001b[K\n",
            "Receiving objects: 100% (14097/14097), 105.66 MiB | 36.05 MiB/s, done.\n",
            "Resolving deltas: 100% (9647/9647), done.\n"
          ]
        }
      ],
      "source": [
        "#Clone the github state of the art\n",
        "!git clone https://github.com/michaelkoepf/vita-epfl-openpifpaf.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the Data\n"
      ],
      "metadata": {
        "id": "GhgdYcECR9_W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-RmwKYfoyPgv"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%bash \n",
        "\n",
        "mkdir data-mscoco  # Create a new directory called \"data-mscoco\".\n",
        "cd data-mscoco  # Change the current working directory to \"data-mscoco\".\n",
        "\n",
        "wget -q -nc http://images.cocodataset.org/annotations/annotations_trainval2017.zip  # Download the annotations file for training and validation data.\n",
        "wget -q -nc http://images.cocodataset.org/annotations/image_info_test2017.zip  # Download the annotations file for the test data.\n",
        "unzip -q -n annotations_trainval2017.zip  # Extract the training and validation annotations.\n",
        "\n",
        "unzip -q -n image_info_test2017.zip  # Extract the test annotations.\n",
        "\n",
        "mkdir images  # Create a new directory called \"images\" inside the \"data-mscoco\" directory.\n",
        "cd images  # Change the current working directory to the \"images\" directory.\n",
        "\n",
        "wget -q -nc http://images.cocodataset.org/zips/val2017.zip  # Download the validation images zip file.\n",
        "wget -q -nc http://images.cocodataset.org/zips/train2017.zip  # Download the training images zip file.\n",
        "wget -q -nc http://images.cocodataset.org/zips/test2017.zip  # Download the test images zip file.\n",
        "\n",
        "unzip -q -n val2017.zip  # Extract the validation images.\n",
        "unzip -q -n train2017.zip  # Extract the training images.\n",
        "unzip -q -n test2017.zip  # Extract the test images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_43cswcyTyp",
        "outputId": "00599703-0660-481f-8052-a4684fb6dcf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m[Errno 2] No such file or directory: '.. # Move back to the previous directory.'\n",
            "/content\n",
            "ln: failed to create symbolic link 'data-mscoco/data-coco': File exists\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!pip install --upgrade pip  # Upgrade pip to the latest version.\n",
        "!pip install --editable \".\"  # Install OpenPifPaf in editable mode.\n",
        "!pip install --editable \".[backbones,dev,test,train]\"  # Install additional dependencies for backbones, dev, test, and train.\n",
        "\n",
        "%cd ..  # Move back to the previous directory.\n",
        "\n",
        "!ln -s /work/vita/datasets/data-coco data-mscoco  # Create a symbolic link to the \"data-coco\" directory as \"data-mscoco\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g0VaDAZPyVpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df18ee6-2466-4c8d-a86d-d2c5971f80c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openpifpaf\n",
            "  Downloading openpifpaf-0.13.11.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.3/202.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata!=3.8.0 (from openpifpaf)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from openpifpaf) (1.22.4)\n",
            "Collecting pysparkling (from openpifpaf)\n",
            "  Downloading pysparkling-0.6.2.tar.gz (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.2/166.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-json-logger (from openpifpaf)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Collecting torch==1.13.1 (from openpifpaf)\n",
            "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "Collecting torchvision==0.14.1 (from openpifpaf)\n",
            "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.0 in /usr/local/lib/python3.10/dist-packages (from openpifpaf) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->openpifpaf) (4.5.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->openpifpaf)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->openpifpaf)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->openpifpaf)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->openpifpaf)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1->openpifpaf) (2.27.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->openpifpaf) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->openpifpaf) (0.40.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=3.8.0->openpifpaf) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2019.3 in /usr/local/lib/python3.10/dist-packages (from pysparkling->openpifpaf) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from pysparkling->openpifpaf) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->pysparkling->openpifpaf) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1->openpifpaf) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1->openpifpaf) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1->openpifpaf) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1->openpifpaf) (3.4)\n",
            "Building wheels for collected packages: openpifpaf, pysparkling\n",
            "  Building wheel for openpifpaf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openpifpaf: filename=openpifpaf-0.13.11-cp310-cp310-linux_x86_64.whl size=11302412 sha256=6015ec1c9f1b96f71a415d0666973769dc0ddf2fee53dd5701b67dc58464d3b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/b8/08/07959dec67c146680770f66246d35138febd2b7d21c733174a\n",
            "  Building wheel for pysparkling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysparkling: filename=pysparkling-0.6.2-py3-none-any.whl size=185883 sha256=61065474b792ea6bb8376e5fb7e56c4476c3f36ef88b5b4d692fab122fca2013\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4e/9f/ebee95d389ea78f11338ba3fe358c09d047f065c4d6ac4cd88\n",
            "Successfully built openpifpaf pysparkling\n",
            "Installing collected packages: python-json-logger, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, importlib-metadata, pysparkling, nvidia-cudnn-cu11, torch, torchvision, openpifpaf\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed importlib-metadata-6.6.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 openpifpaf-0.13.11 pysparkling-0.6.2 python-json-logger-2.0.7 torch-1.13.1 torchvision-0.14.1\n"
          ]
        }
      ],
      "source": [
        "# Install openpifpaf package\n",
        "!pip install openpifpaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkn6ZS3VyaJg",
        "outputId": "66f8ec83-756d-41bb-94db-1ff7307f5f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder structure created: /content/test\n",
            "File created: /content/test/checkpoints/job.pt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Create the main folder\n",
        "folder_path = '/content/test'\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "# The os.makedirs() function creates the main folder at the specified path '/content/test'.\n",
        "# The exist_ok=True parameter ensures that the function doesn't raise an exception if the folder already exists.\n",
        "\n",
        "# Create the subfolder\n",
        "subfolder_path = os.path.join(folder_path, 'checkpoints')\n",
        "os.makedirs(subfolder_path, exist_ok=True)\n",
        "# The os.path.join() function is used to combine the main folder path with the subfolder name ('checkpoints').\n",
        "# The os.makedirs() function creates the subfolder at the specified path.\n",
        "# The exist_ok=True parameter ensures that the function doesn't raise an exception if the folder already exists.\n",
        "\n",
        "# Create the file inside the subfolder\n",
        "file_path = os.path.join(subfolder_path, 'job.pt')\n",
        "open(file_path, 'w').close()\n",
        "# The os.path.join() function is used to combine the subfolder path with the file name ('job.pt').\n",
        "# The open() function is used to create the file at the specified path.\n",
        "# The mode 'w' indicates that the file is opened in write mode.\n",
        "# The .close() method is immediately called to close the file after creating it.\n",
        "\n",
        "print(f\"Folder structure created: {folder_path}\")\n",
        "print(f\"File created: {file_path}\")\n",
        "# Print statements to confirm the successful creation of the folder structure and the file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade pip package installer\n",
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L29MaLcob4US",
        "outputId": "c67d44ee-a6d5-4693-b1fc-42f6549387b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install openpifpaf-vita package\n",
        "!pip install openpifpaf-vita\n",
        "\n",
        "# Install matplotlib package\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mRF04HLcHiO",
        "outputId": "e7dc1edc-969f-41df-fe54-aa91666b7da3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpifpaf-vita in /usr/local/lib/python3.10/dist-packages/openpifpaf_vita-0.14.0+18.g0b83607.dirty-py3.10-linux-x86_64.egg (0.14.0+18.g0b83607.dirty)\n",
            "Requirement already satisfied: importlib_metadata!=3.8.0 in /usr/local/lib/python3.10/dist-packages (from openpifpaf-vita) (6.6.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from openpifpaf-vita) (1.22.4)\n",
            "Requirement already satisfied: pysparkling in /usr/local/lib/python3.10/dist-packages (from openpifpaf-vita) (0.6.2)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.10/dist-packages (from openpifpaf-vita) (2.0.7)\n",
            "INFO: pip is looking at multiple versions of openpifpaf-vita to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openpifpaf-vita\n",
            "  Using cached openpifpaf-vita-0.14.0.tar.gz (224 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to '/content/vita-epfl-openpifpaf'\n",
        "%cd /content/vita-epfl-openpifpaf\n",
        "\n",
        "# Install the package with additional dependencies\n",
        "!pip install --no-cache-dir --editable '.[train,test,coreml,backbones]'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OUu8RCWZaw3",
        "outputId": "0ca1f9e9-fbd2-462e-9aad-341c1d7526c5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vita-epfl-openpifpaf\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/vita-epfl-openpifpaf\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-s9gEVZycjg",
        "outputId": "47364b03-150f-4403-ae17-75c57be4041d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: python3 -m openpifpaf.train [options]\n",
            "python3 -m openpifpaf.train: error: unrecognized arguments: --hrformer-checkpoint=content/hrt_tiny.pth\n"
          ]
        }
      ],
      "source": [
        "# Run openpifpaf training with the specified arguments\n",
        "!python3 -m openpifpaf.train --ddp \\\n",
        "  --dataset=cocokp \\\n",
        "  --cocokp-square-edge=193 \\\n",
        "  --cocokp-extended-scale \\\n",
        "  --cocokp-orientation-invariant=0.1 \\\n",
        "  --cocokp-upsample=2 \\\n",
        "  --cocokp-train-annotations=/content/data-mscoco/annotations/person_keypoints_train2017.json \\\n",
        "  --cocokp-val-annotations=/content/data-mscoco/annotations/person_keypoints_val2017.json \\\n",
        "  --cocokp-train-image-dir=/content/data-mscoco/images/train2017/ \\\n",
        "  --cocokp-val-image-dir=/content/data-mscoco/images/val2017/ \\\n",
        "  --basenet=resnet50 \\\n",
        "  --epochs=1 \\\n",
        "  --batch-size=4 \\\n",
        "  --momentum=0.95 \\\n",
        "  --lr=0.001 \\\n",
        "  --output /content/test/checkpoints/job.pt \\\n",
        "  --log-interval=2 \\\n",
        "  --basenet=hrformer_t \\\n",
        "  --hrformer-checkpoint=content/hrt_tiny.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch /content/test_results"
      ],
      "metadata": {
        "id": "0Ty8smSOvphR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPfKbpN0mW05"
      },
      "outputs": [],
      "source": [
        "!python3 -m openpifpaf.predict \\  # Run the 'predict' module of OpenPifPaf\n",
        "    --checkpoint /content/test/checkpoints/job.pt \\  # Path to the trained model checkpoint\n",
        "    --image-dir /content/data-mscoco/images/test2017/ \\  # Directory containing test images\n",
        "    --output-dir /content/test_results  # Directory to save the output predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "B7i5FBjkm57i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "zd-4fLPz2arJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy1uk0Lp5xsS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhtYdtznZwJfce3PHQ9a/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}